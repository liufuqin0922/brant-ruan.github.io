---
title: Coursera | Machine Learning Notes
category: CS
---

## Coursera | Machine Learning Notes

### Preface

**All the resources here belong to Andrew Ng and relative staffs.**  
**I download them from [Coursera](https://www.coursera.org/).**  
**Sincerely, thanks for your teaching and your sharing of knowledge and technique.**  

![]({{ site.url }}/resources/pictures/ML-final.jpg)

### Slides

|0|1|2|3|4|5|
|:-:|:-:|:-:|:-:|:-:|:-:|
|[Lecture1.pdf]({{ site.url }}/resources/pdf/Lecture1.pdf)|[Lecture2.pdf]({{ site.url }}/resources/pdf/Lecture2.pdf)|[Lecture3.pdf]({{ site.url }}/resources/pdf/Lecture3.pdf)|[Lecture4.pdf]({{ site.url }}/resources/pdf/Lecture4.pdf)|[Lecture5.pdf]({{ site.url }}/resources/pdf/Lecture5.pdf)|[Lecture6.pdf]({{ site.url }}/resources/pdf/Lecture6.pdf)|
|[Lecture7.pdf]({{ site.url }}/resources/pdf/Lecture7.pdf)|[Lecture8.pdf]({{ site.url }}/resources/pdf/Lecture8.pdf)|[Lecture9.pdf]({{ site.url }}/resources/pdf/Lecture9.pdf)|[Lecture10.pdf]({{ site.url }}/resources/pdf/Lecture10.pdf)|[Lecture11.pdf]({{ site.url }}/resources/pdf/Lecture11.pdf)|[Lecture12.pdf]({{ site.url }}/resources/pdf/Lecture12.pdf)|
|[Lecture13.pdf]({{ site.url }}/resources/pdf/Lecture13.pdf)|[Lecture14.pdf]({{ site.url }}/resources/pdf/Lecture14.pdf)|[Lecture15.pdf]({{ site.url }}/resources/pdf/Lecture15.pdf)|[Lecture16.pdf]({{ site.url }}/resources/pdf/Lecture16.pdf)|[Lecture17.pdf]({{ site.url }}/resources/pdf/Lecture17.pdf)|[Lecture18.pdf]({{ site.url }}/resources/pdf/Lecture18.pdf)|

### Notes

#### Week 1

#### Week 2

#### Week 3

#### Week 4

#### Week 5

##### Basic Knowledge

I Found that the Resources on the web site are very useful.

##### BPNN Implement Notes

When implementing BPNN, you should be clear about the exact definition of `z` and `a`, that is:

{% highlight matlab %}
delta2 = zeros(hidden_layer_size, 1);
delta3 = zeros(num_labels, 1);
Delta2 = zeros(hidden_layer_size, input_layer_size + 1);
Delta3 = zeros(num_labels, hidden_layer_size + 1);

for t = 1:m,
% Note that we have put bias unit in X above
	a1 = transpose(X(t, :));
	% Feedforward
	z2 = Theta1 * a1;
	a2 = [1; sigmoid(z2)];
	z3 = Theta2 * a2;
	a3 = sigmoid(z3);
% backpropagation
	temp_y = zeros(num_labels, 1);
	temp_y(y(t)) = 1;
	delta3 = a3 - temp_y;
	delta2 = (transpose(Theta2) * delta3)(2:end) .* sigmoidGradient(z2);
	Delta3 = Delta3 + delta3 * transpose(a2);
	Delta2 = Delta2 + delta2 * transpose(a1);
end

Theta1_grad = Delta2 ./ m;
Theta2_grad = Delta3 ./ m;
{% endhighlight %}

Be clear that there exists only bias for `a` and no bias for `z`. And layer `l` doesn't contribute to the `bias` in layer `i+1`. So note that

```
z2 = Theta1 * a1;
z2 = [1; z2];
a2 = sigmoid(z2);
```

is **WRONG**. You should calculate as

```
z2 = Theta1 * a1;
a2 = [1; sigmoid(z2)];
```

Finally, pay attention to the size of `delta` and `Delta`.

##### BPNN (Vectorization)

See

> https://www.coursera.org/learn/machine-learning/programming/AiHgN/neural-network-learning/discussions/threads/QFnrpQckEeWv5yIAC00Eog  
> https://www.coursera.org/learn/machine-learning/discussions/all/threads/a8Kce_WxEeS16yIACyoj1Q  
> https://www.coursera.org/learn/machine-learning/resources/Uuxg6  

{% highlight matlab %}
X = [ones(m, 1) X];
A1 = transpose(X);
Z2 = Theta1 * A1;
A2 = sigmoid(Z2);
A2 = [ones(1, size(A2)(2)); A2];
Z3 = Theta2 * A2;
A3 = transpose(sigmoid(Z3)); % A3 is 5000 * 10
vtemp_y = eye(num_labels)(y, :); % trick!
vdelta3 = A3 - vtemp_y;
vdelta2 = (vdelta3 * Theta2)(:, 2:end) .* sigmoidGradient(transpose(Z2));
vDelta3 = transpose(vdelta3) * transpose(A2);
vDelta2 = transpose(vdelta2) * transpose(A1);

J = sum(sum(-vtemp_y .* log(A3) - (1 - vtemp_y) .* log(1 - A3)));
J = J / m;
J = J + (lambda / (2 * m)) * (sum(sum(Theta1(:, 2:end) .^ 2)) ...
	+ sum(sum(Theta2(:, 2:end) .^ 2)));
{% endhighlight %}

**There are some tricks.**

Expand `y` to `m * K`:

```
vtemp_y = eye(num_labels)(y, :);
```

This is an index trick about which I do not know the details.

Another trick which can do the same thing:

```
vtemp_y = [1:num_labels] == y;
```

You can use this trick since version 3.6.0 of Octave. That is `Broadcasting` feature. When `==` operating is going, `[1:num_labels]` vector will be currently expanded to `m * num_labels` and `y` will be currently expanded to `m * num_labels`.

See [GNU Octave Doc](http://www.gnu.org/software/octave/doc/interpreter/Broadcasting.html) for more details.

Use `trace` or `sum(sum())` to calculate the sum of matrix:

```
J = sum(sum(-vtemp_y .* log(A3) - (1 - vtemp_y) .* log(1 - A3)));
```

The vectorization method is much faster than `for` iteration!

##### Bonus: Classify Your Own Images of Digits

See

> https://www.coursera.org/learn/machine-learning/resources/EcbzQ

We will use image below:

![]({{ site.url }}/resources/pictures/ml-four.jpg)

Our classifier in `ex4` needs 20*20 pixels black and white images converted in a row vector of 400 real numbers.

Each pixel is represented by a real number between -1.0 to 1.0, meaning -1.0 equal black and 1.0 equal white.

Steps:

- Load images(.jpg)
- Convert to black&white
- Cropping to square image
- Scaling to 20*20 pixels
- Black&white to gray&white
- Rotation of image

Then you have a sample like that in the training data set. And use the classifier to predict the converted image.

Follow in code:

{% highlight matlab %}
function vectorImage = imageTo20x20Gray(fileName, cropPercentage=0, rotStep=0)
% Read as RGB image
Image3DmatrixRGB = imread(fileName);
% Convert to NTSC image (YIQ)
Image3DmatrixYIQ = rgb2ntsc(Image3DmatrixRGB);
% Convert to grays keeping only luminance (Y) and discard chrominance (IQ)
Image2DmatrixBW  = Image3DmatrixYIQ(:,:,1);
% Get the size of your image
oldSize = size(Image2DmatrixBW);
% Obtain crop size toward centered square (cropDelta)
cropDelta = floor((oldSize - min(oldSize)) .* (cropPercentage/100));
% Compute the desired final pixel size for the original image
finalSize = oldSize - cropDelta;
% Compute each dimension origin for croping
cropOrigin = floor(cropDelta / 2) + 1;
% Compute each dimension copying size
copySize = cropOrigin + finalSize - 1;
% Copy just the desired cropped image from the original B&W image
croppedImage = Image2DmatrixBW( ...
	cropOrigin(1):copySize(1), cropOrigin(2):copySize(2));
% Resolution scale factors: [rows cols]
scale = [20 20] ./ finalSize;
% Compute back the new image size (extra step to keep code general)
newSize = max(floor(scale .* finalSize),1); 
% Compute a re-sampled set of indices:
rowIndex = min(round(((1:newSize(1))-0.5)./scale(1)+0.5), finalSize(1));
colIndex = min(round(((1:newSize(2))-0.5)./scale(2)+0.5), finalSize(2));
% Copy just the indexed values from old image to get new image
newImage = croppedImage(rowIndex,colIndex,:);
% Rotate if needed: -1 is CCW, 0 is no rotate, 1 is CW
newAlignedImage = rot90(newImage, rotStep);
% Invert black and white
invertedImage = - newAlignedImage;
% Find min and max grays values in the image
maxValue = max(invertedImage(:));
minValue = min(invertedImage(:));
% Compute the value range of actual grays
delta = maxValue - minValue;
% Normalize grays between 0 and 1
normImage = (invertedImage - minValue) / delta;
% Add contrast. Multiplication factor is contrast control.
contrastedImage = sigmoid((normImage -0.5) * 5);
% Show image as seen by the classifier
imshow(contrastedImage, [-1, 1] );
% Output the matrix as a unrolled vector
vectorImage = reshape(contrastedImage, 1, newSize(1)*newSize(2));
end
{% endhighlight %}

Finally, you can see the result:

![]({{ site.url }}/resources/pictures/ml-graywhite-four.jpg)

#### Week 6

##### Notes on validationCurve.m

Firstly I use

{% highlight matlab %}
for i = 1:length(lambda_vec)
	theta_train = trainLinearReg(X, y, lambda_vec(i));
	error_train(i) = linearRegCostFunction(X, y, theta_train, lambda_vec(i));
	error_val(i) = linearRegCostFunction(Xval, yval, theta_train, lambda_vec(i));
end
{% endhighlight %}

And what I got is like below:

![]({{ site.url }}/resources/pictures/ml-validationCurve-wrong.jpg)

And after I learnt from [here](https://www.coursera.org/learn/machine-learning/discussions/all/threads/AdGhzAX1EeWyEyIAC7PmUA/replies/7XjBAQ-MEeWUtiIAC9TNkg?page=2) I find the trick:

The lambda should only used in training and should not be used in calculating the real error. So you should use 0 instead of lambda in the calculation of error_train and error_val.

Correct code is:

{% highlight matlab %}
for i = 1:length(lambda_vec)
	theta_train = trainLinearReg(X, y, lambda_vec(i));
	error_train(i) = linearRegCostFunction(X, y, theta_train, 0);
	error_val(i) = linearRegCostFunction(Xval, yval, theta_train, 0);
end
{% endhighlight %}

And the curve is very beautiful now:

![]({{ site.url }}/resources/pictures/ml-validationCurve-right.jpg)

##### mu,sigma Wrong Comprehension

> Question I asked on Coursera (Now it seems silly).

In *ex5.m Part 6*: Feature Mapping for Polynomial Regression:

{% highlight matlab %}
% Map X onto Polynomial Features and Normalize
X_poly = polyFeatures(X, p);
[X_poly, mu, sigma] = featureNormalize(X_poly);  % Normalize
X_poly = [ones(m, 1), X_poly];                   % Add Ones

% Map X_poly_test and normalize (using mu and sigma)
X_poly_test = polyFeatures(Xtest, p);
X_poly_test = bsxfun(@minus, X_poly_test, mu);
X_poly_test = bsxfun(@rdivide, X_poly_test, sigma);
X_poly_test = [ones(size(X_poly_test, 1), 1), X_poly_test];         % Add Ones

% Map X_poly_val and normalize (using mu and sigma)
X_poly_val = polyFeatures(Xval, p);
X_poly_val = bsxfun(@minus, X_poly_val, mu);
X_poly_val = bsxfun(@rdivide, X_poly_val, sigma);
X_poly_val = [ones(size(X_poly_val, 1), 1), X_poly_val];           % Add Ones
{% endhighlight %}

As the code above, it firstly uses `featureNormalize` to calculate `mu` and `sigma` for `X_poly`, and that is OK. But why can the same `mu` and `sigma` be applied to the calculation of `X_poly_test` and `X_poly_val`?

Notice that in `featureNormalize`:

{% highlight matlab %}
mu = mean(X);
sigma = std(X_norm);
{% endhighlight %}

So I think both `mu` and `sigma` need to be different with different data set. That is, we need to use `featureNormalize()` for three times.

**Correct Comprehension**

(Also posted on Coursera)

I'm sorry and I reviewed the feature scaling slides. I'm wrong.

The `mu` and `sigma` must be consistent among the `train set`, `cv set` and `test set`. Otherwise, the train results (`theta`) will make no sense because of wrong inputs in `cv set` and `test set`.

#### Week 7

##### Basic Knowledge

For more details about SVM, refer to [www.zhihu.com/question/21094489](https://www.zhihu.com/question/21094489).  
For more details about `kernel`, refer to [www.zhihu.com/question/30371867](https://www.zhihu.com/question/30371867).

#### Week 8

#### Week 9

> When developing a learning algorithm (choosing features, etc.), making decisions is much easier if we have a way of evaluating our learning algorithm.



#### Week 10

#### Week 11

### Summary

**Thank you, Andrew Ng, Tom and other staffs!**

### Programming Tasks

|0|1|2|3|
|:-:|:-:|:-:|:-:|
|[machine-learning-ex1.zip]({{ site.url }}/resources/code/machine-learning-ex1.zip)|[machine-learning-ex2.zip]({{ site.url }}/resources/code/machine-learning-ex2.zip)|[machine-learning-ex3.zip]({{ site.url }}/resources/code/machine-learning-ex3.zip)|[machine-learning-ex4.zip]({{ site.url }}/resources/code/machine-learning-ex4.zip)|
|[machine-learning-ex5.zip]({{ site.url }}/resources/code/machine-learning-ex5.zip)|[machine-learning-ex6.zip]({{ site.url }}/resources/code/machine-learning-ex6.zip)|[machine-learning-ex7.zip]({{ site.url }}/resources/code/machine-learning-ex7.zip)|[machine-learning-ex8.zip]({{ site.url }}/resources/code/machine-learning-ex8.zip)|

### Reference

- [Coursera: Machine Learning](https://www.coursera.org/learn/machine-learning/)